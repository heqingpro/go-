### redis

#### 一、基础

##### 1、基础数据 5种

- string

  - 缓存
  - 计数器
  - session

- list

  - 消息队列

- hash

  - 缓存 更直观，维护关系

- set

  - 标签
  - 点赞

- zset

  - 排行榜


##### 2、持久化

- AOF

  - AOF重写

    AOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。

- RDB

##### 3、缓存穿透

  缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。

- **解决方法**

  最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。

  - **1、缓存无效 key**

    如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： `SET key value EX 10086` 

  - **2、布隆过滤器**

    把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。

    我们先来看一下，**当一个元素加入布隆过滤器中的时候，会进行哪些操作：**

    1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
    2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。

    我们再来看一下，**当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：**

    1. 对给定元素再次进行相同的哈希计算；
    2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

##### 4、缓存雪崩

​		**缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。** 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。

- **解决方法**
  - **针对 Redis 服务不可用的情况：**
    1. 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
    2. 限流，避免同时处理大量的请求。
  - **针对热点缓存失效的情况：**
    1. 设置不同的失效时间比如随机设置缓存的失效时间。
    2. 缓存永不失效。

##### 5、如何保证缓存和数据库数据的一致性？

- **Cache Aside Pattern（旁路缓存模式）**

​		Cache Aside Pattern 中遇到写请求是这样的：更新 DB，然后直接删除 cache 

​		如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：

  			1、**缓存失效时间变短（不推荐，治标不治本）** ：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。

​			  2、**增加 cache 更新重试机制（常用）**： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。

- 方法
  - **1、先更新数据库--删除缓存--（删除失败--消息队列kafka）**
    - 读写分离 + 主从复制延迟 时不一致 采用延时双删
  - **2、订阅数据库变更日志(binlog[阿里canal]--再操作缓存**

##### 5、redis 分布式锁

- 存在问题：
  - **死锁**：设置过期时间
  - **过期时间评估不好，锁提前过期**：守护线程，自动续期（java redission）
  - **锁被别人释放**：锁写入唯一标识，释放锁先检查标识，再释放

- **操作步骤：**

  1. 加锁：`SET lock_key $unique_id EX $expire_time NX`
  2. 操作共享资源
  3. 释放锁：Lua 脚本，先 GET 判断锁是否归属自己（unique_id），再 DEL 释放锁

- **redis集群存在问题**

  主从切换后，锁可能会丢失

  -  **Redlock（红锁）** redis 作者提出的方案

    1. 不再需要部署**从库**和**哨兵**实例，只部署**主库**
    2. 但主库要部署多个，官方推荐至少 5 个实例

    - **步骤：**

    1. 客户端先获取「当前时间戳T1」
    2. 客户端依次向这 5 个 Redis 实例发起加锁请求（用前面讲到的 SET 命令），且每个请求会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（包括网络超时、锁被其它人持有等各种异常情况），就立即向下一个 Redis 实例申请加锁
    3. 如果客户端从 >=3 个（大多数）以上 Redis 实例加锁成功，则再次获取「当前时间戳T2」，如果 T2 - T1 < 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败
    4. 加锁成功，去操作共享资源（例如修改 MySQL 某一行，或发起一个 API 请求）
    5. 加锁失败，向「全部节点」发起释放锁请求（前面讲到的 Lua 脚本释放锁）

    - **存在问题：**

      Redlock 只有建立在「时钟正确」的前提下，才能正常工作

##### 6、Zookeeper 分布式锁

Zookeeper 不像 Redis 那样，需要考虑锁的过期时间问题，它是采用了「临时节点」，保证客户端 1 拿到锁后，只要连接不断，就可以一直持有锁。而且，如果客户端 1 异常崩溃了，那么这个临时节点会自动删除，保证了锁一定会被释放。

- **操作步骤：**
  1. 客户端 1 和 2 都尝试创建「临时节点」，例如 /lock
  2. 假设客户端 1 先到达，则加锁成功，客户端 2 加锁失败
  3. 客户端 1 操作共享资源
  4. 客户端 1 删除 /lock 节点，释放锁
- **存在问题**
  - **客户端 1 此时会与 Zookeeper 服务器维护一个 Session，这个 Session 会依赖客户端「定时心跳」来维持连接**。如果 Zookeeper 长时间收不到客户端的心跳，就认为这个 Session 过期了，也会把这个临时节点删除。可见，即使是使用 Zookeeper，也无法保证进程 GC、网络延迟异常场景下的安全性。

- **对比redis方案：**

  **Zookeeper 的优点：**

  1. 不需要考虑锁的过期时间
  2. watch 机制，加锁失败，可以 watch 等待锁释放，实现乐观锁

  **但它的劣势是：**

  1. 性能不如 Redis
  2. 部署和运维成本高
  3. 客户端与 Zookeeper 的长时间失联，锁被释放问题

##### 7、底层数据结构

- SDS - simple synamic string - 支持自动动态扩容的字节数组
- list - 平平无奇的链表
- dict - 使用双哈希表实现的, 支持平滑扩容的字典
- zskiplist - 附加了后向指针的跳跃表
- intset - 用于存储整数数值集合的自有结构
- ziplist - 一种实现上类似于TLV, 但比TLV复杂的, 用于存储任意数据的有序序列的数据结构
- quicklist - 一种以ziplist作为结点的双链表结构, 实现的非常苟
- zipmap - 一种用于在小规模场合使用的轻量级字典结构

##### 8、内存淘汰算法

Redis 提供 6 种数据淘汰策略：

1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）
5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

4.0 版本后增加以下两种：

1. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰
2. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

#### 二、集群策略

##### 一、主从复制

一主多从

- 同步原理:

  主从redis建立连接后，根据runid 及复制偏移量进行同步，首次同步先同步RDB快照，然后根据偏移量同步缓存数据

- 无法水平扩容

##### 2、哨兵

监控主从数据库是否正常运行，master出现故障时，自动将它的其中一个slave转化为master。

- 无法水平扩容
- 自动切换slave 和master

##### 3、集群

- 1、redis-cluster

  - 无中心架构，每个节点都与其他所有节点连接

  - redis-cluster把所有的物理节点映射到[0,16383]slot（槽）上，cluster负责维护node--slot--value。

    集群预先给所有节点分好16384个桶，每个节点得到部分桶，当需要在redis集群中插入数据时，根据CRC16(KEY) mod 16384的值，决定将一个key放到哪个桶中。

    为了增加集群的可访问性，官方推荐的方案是将node配置成主从结构，即一个master主节点，挂n个slave从节点。如果主节点失效，redis cluster会根据选举算法从slave节点中选择一个上升为master节点，整个集群继续对外提供服务。


- 2、中间件
  - twemproxy
  - codis

- 3、 客户端分片

  - 一致性哈希算法

    - 只影响相邻节点key分配，影响量小。

    



 